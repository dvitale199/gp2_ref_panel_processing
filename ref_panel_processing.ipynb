{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shell_do(command, log=False, return_log=False):\n",
    "    print(f'Executing: {(\" \").join(command.split())}', file=sys.stderr)\n",
    "\n",
    "    res=subprocess.run(command.split(), stdout=subprocess.PIPE)\n",
    "\n",
    "    if log:\n",
    "        print(res.stdout.decode('utf-8'))\n",
    "    if return_log:\n",
    "        return(res.stdout.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dir_path = f'/data/LNG/vitaled2/1kgenomes'\n",
    "ashk_data = f'/data/LNG/iwakih2/dataset/Jew/GSE23636'\n",
    "onekg_demog_path = f'{ref_dir_path}/igsr_samples.tsv'\n",
    "out_ancestry_file = f'{ref_dir_path}/ref_panel_ancestry.txt'\n",
    "ref_panel = f'{ref_dir_path}/1kg_ashkj_ref_panel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create list of Ashkenazis by FID and IID\n",
    "ashk = pd.read_csv(f'{ashk_data}.fam', header=None, sep=' ')\n",
    "\n",
    "# add ashkenazis with labels to df\n",
    "ancestry = pd.DataFrame()\n",
    "ancestry[['FID','IID']], ancestry['label'] = ashk[[0,1]], 'AJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read 1kG and label \n",
    "onekg_demog = pd.read_csv(onekg_demog_path, sep='\\t')\n",
    "onekg_demog['FID'], onekg_demog['IID'] = onekg_demog['Sample name'], onekg_demog['Sample name']\n",
    "onekg_demog['label'] = onekg_demog['Superpopulation code']\n",
    "\n",
    "# create separate label for African American (ASW) and Caribbean (ACB) label to AAC to match Neuro+\n",
    "onekg_demog.loc[(onekg_demog['Population code'] == 'ASW') | (onekg_demog['Population code'] == 'ACB'), 'label'] = 'AAC'\n",
    "\n",
    "# create separate label for Finnish (FIN) to match Neuro+\n",
    "onekg_demog.loc[onekg_demog['Population code'] == 'FIN', 'label'] = 'FIN'\n",
    "onekg_demog.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all populations in GP2 are present.... Add Ashkenazi (AJ) and EXCLUDE FINNISH!!!!\n",
    "#figure out the situation with CHD\n",
    "pop_dict = {\n",
    "    'AMR': ['MXL','CLM','PEL','PUR'],\n",
    "    'EAS': ['JPT','CDX','CHB','CHS','KHV','CHD'],\n",
    "    'EUR': ['TSI','IBS','GBR','CEU', 'AJ', 'FIN'],\n",
    "    'SAS': ['PJL','ITU','STU','GIH','BEB'],\n",
    "    'AFR': ['GWD','MSL','ESN','GWJ','YRI','LWK','GWF','GWW'],\n",
    "    'AAC': ['ASW','ACB']\n",
    "}\n",
    "\n",
    "pop_list = [pop for poplist in [pop for supergroup, pop in pop_dict.items()] for pop in poplist]\n",
    "\n",
    "print('Counts per population code in 1kG')\n",
    "total = 0\n",
    "for pop in pop_list:\n",
    "    count = (onekg_demog['Population code'] == pop).sum()\n",
    "    print(pop, count)\n",
    "    total += count\n",
    "    \n",
    "print(f'Total across population codes in 1kG: {total}')\n",
    "print()\n",
    "# keep only onekg_demog populations that are in population list (pops in neuro+ chip, given by GP2)\n",
    "onekg_demog = onekg_demog.loc[onekg_demog['Population code'].isin(pop_list)]\n",
    "\n",
    "#append onekg_demog to ancestry\n",
    "ancestry_final = ancestry.append(onekg_demog[['FID','IID','label']], ignore_index=True)\n",
    "ancestry_final.to_csv(out_ancestry_file, header=True, index=False, sep='\\t')\n",
    "ancestry_final[['FID','IID']].to_csv(f'{ref_dir_path}/gp2_keep.txt', sep='\\t', header=None, index=None)\n",
    "print()\n",
    "print('Counts per superpopulation code in 1kG + Ashkenazi')\n",
    "print(ancestry_final.label.value_counts(dropna=False))\n",
    "print(f'Total across superpopulation codes in 1kG + Ashkenazi: {ancestry_final.label.value_counts(dropna=False).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune the shit out of the ref panel to prep for ancestry test\n",
    "# keep only country codes found in GP2 neuro+ chip (excluding Finnish and including Ashkenazis)\n",
    "ref_panel_prune1 = f'{ref_panel}_maf_geno_hwe'\n",
    "ref_panel_final_prune = f'{ref_panel}_gp2_pruned'\n",
    "\n",
    "plink_cmd1 = f'plink --bfile {ref_panel}\\\n",
    " --maf 0.05\\\n",
    " --geno 0.01\\\n",
    " --hwe 0.0001\\\n",
    " --autosome\\\n",
    " --keep {ref_dir_path}/gp2_keep.txt\\\n",
    " --exclude {ref_dir_path}/hg38_exclusion_regions.txt\\\n",
    " --make-bed\\\n",
    " --out {ref_panel_prune1}' \n",
    "\n",
    "plink_cmd2 = f'plink --bfile {ref_panel_prune1}\\\n",
    " --indep-pairwise 1000 10 0.02\\\n",
    " --autosome\\\n",
    " --out {ref_dir_path}/pruned_data'\n",
    "\n",
    "plink_cmd3 = f'plink --bfile {ref_panel_prune1}\\\n",
    " --extract {ref_dir_path}/pruned_data.prune.in\\\n",
    " --make-bed\\\n",
    " --out {ref_panel_final_prune}'\n",
    "\n",
    "cmds = [plink_cmd1, plink_cmd2, plink_cmd3]\n",
    "\n",
    "# for cmd in cmds:\n",
    "#     shell_do(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, merge ancestry with pruned ref panel to see how many in each ancestry group\n",
    "pruned_ref_fam = pd.read_csv(f'{ref_panel_final_prune}.fam', sep=' ', header=None)\n",
    "total_pruned_ref_df = pruned_ref_fam.merge(ancestry_final, how='left', left_on=[0,1], right_on=['FID','IID'])\n",
    "\n",
    "total_pruned_ref_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastStructure test with Ref Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, test with faststructure\n",
    "ref_panel = f'{ref_dir_path}/1kg_ashkj_ref_panel_gp2_pruned'\n",
    "ancestry_labels = f'{ref_dir_path}/ref_panel_ancestry.txt'\n",
    "structure_out = '/data/vitaled2/ref_panel/temp/1kg_ashkj_ref_panel_gp2_structure'\n",
    "fam = pd.read_csv(f'{ref_panel}.fam', sep=' ', header=None)\n",
    "structure = f'/data/vitaled2/ref_panel/fastStructure/structure.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_run = f'python {structure}\\\n",
    " -K 8\\\n",
    " --input={ref_panel}\\\n",
    " --output={structure_out}'\n",
    "\n",
    "# # need to run in terminal in conda virtualenv with python2\n",
    "print(structure_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after fastStructure finishes running:\n",
    "# read Q file and create labels\n",
    "q_df = pd.read_csv(f'{structure_out}.8.meanQ', header=None, sep='\\s+')\n",
    "q_df.columns = [f'pop{i}' for i in range(1,9)]\n",
    "fam['highest_2_pops'] = q_df.apply(lambda s: s.abs().nlargest(2).index.tolist(), axis=1)\n",
    "fam['highest_pop'] = q_df.idxmax(axis=1)\n",
    "\n",
    "q_df['FID'], q_df['IID'], q_df['highest_pop'], q_df['highest_2_pops'] = fam[0], fam[1], fam['highest_pop'], fam['highest_2_pops']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(ancestry_labels, sep='\\t')\n",
    "q_pop_merged = q_df.merge(pop, left_on=['FID','IID'], right_on=['FID','IID'])\n",
    "print(q_pop_merged['highest_pop'].value_counts())\n",
    "# q_pop_merged['label'].value_counts()\n",
    "q_pop_merged.to_csv(f'{ref_dir_path}/pca_labeled_faststructure.txt', sep='\\t', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pop_merged.describe()\n",
    "q_pop_merged['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pop_merged[q_pop_merged['label'] == 'AJ'].describe() # almost 100% pop7\n",
    "q_pop_merged[q_pop_merged['label'] == 'EUR'].describe() # almost 100% pop5, next highest mean is pop8 which makes sense\n",
    "q_pop_merged[q_pop_merged['label'] == 'FIN'].describe() # almost 100% pop5 ... FIN is questionable as not really unique, how does this work with PCA?\n",
    "q_pop_merged[q_pop_merged['label'] == 'EAS'].describe() # almost 93% pop3\n",
    "q_pop_merged[q_pop_merged['label'] == 'AMR'].describe() # 53% POP5 and 37% POP6\n",
    "q_pop_merged[q_pop_merged['label'] == 'SAS'].describe() # almost 95% POP8\n",
    "q_pop_merged[q_pop_merged['label'] == 'AAC'].describe() # almost 90% POP1\n",
    "q_pop_merged[q_pop_merged['label'] == 'AFR'].describe() # almost 100% POP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop2 only contains 1 sample\n",
    "high_pop2_df = q_pop_merged[q_pop_merged['pop2'] > 0.8]\n",
    "high_pop2_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove samples\n",
    "high_pop2_df[['FID','IID']].to_csv('/data/vitaled2/ref_panel/rm_samples.txt', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now remove samples with plink\n",
    "\n",
    "plink_rm_cmd = f'plink --bfile {ref_panel}\\\n",
    " --maf 0.05\\\n",
    " --geno 0.01\\\n",
    " --hwe 0.0001\\\n",
    " --autosome\\\n",
    " --remove /data/vitaled2/ref_panel/rm_samples.txt\\\n",
    " --make-bed\\\n",
    " --out {ref_panel}_final' \n",
    "\n",
    "# shell_do(plink_rm_cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, run faststructure with removed rogue sample\n",
    "structure_run2 = f'python {structure}\\\n",
    " -K 8\\\n",
    " --input={ref_panel}_final\\\n",
    " --output={ref_panel}_final_structure'\n",
    "\n",
    "# need to run in terminal in conda virtualenv with python2\n",
    "print(structure_run2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, take a look at faststructure after removing rogue sample\n",
    "q_df = pd.read_csv(f'{ref_panel}_final_structure.8.meanQ', header=None, sep='\\s+')\n",
    "q_df.columns = [f'pop{i}' for i in range(1,9)]\n",
    "fam['highest_2_pops'] = q_df.apply(lambda s: s.abs().nlargest(2).index.tolist(), axis=1)\n",
    "fam['highest_pop'] = q_df.idxmax(axis=1)\n",
    "\n",
    "q_df['FID'], q_df['IID'], q_df['highest_pop'], q_df['highest_2_pops'] = fam[0], fam[1], fam['highest_pop'], fam['highest_2_pops']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_csv(ancestry_labels, sep='\\t')\n",
    "q_pop_merged = q_df.merge(pop, left_on=['FID','IID'], right_on=['FID','IID'])\n",
    "print(q_pop_merged['highest_pop'].value_counts())\n",
    "# q_pop_merged['label'].value_counts()\n",
    "q_pop_merged.to_csv(f'{ref_dir_path}/labeled_faststructure.txt', sep='\\t', header=True, index=False)\n",
    "q_pop_merged['label'].to_csv(f'{ref_dir_path}/faststructure_labels.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pop_merged.describe()\n",
    "# q_pop_merged['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pop_merged[q_pop_merged['label'] == 'AJ'].describe() # almost 100% pop4\n",
    "# q_pop_merged[q_pop_merged['label'] == 'EUR'].describe() # almost 100% pop8, next highest mean is pop4 which makes sense\n",
    "# q_pop_merged[q_pop_merged['label'] == 'FIN'].describe() # almost 100% pop8\n",
    "# q_pop_merged[q_pop_merged['label'] == 'EAS'].describe() # almost 89% pop6, 10% POP5\n",
    "# q_pop_merged[q_pop_merged['label'] == 'AMR'].describe() # 50% POP8 and 40% POP2\n",
    "# q_pop_merged[q_pop_merged['label'] == 'SAS'].describe() # almost 91% POP3\n",
    "# q_pop_merged[q_pop_merged['label'] == 'AAC'].describe() # 82% POP7 13% POP8\n",
    "# q_pop_merged[q_pop_merged['label'] == 'AFR'].describe() # almost 91% POP7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distruct run for visualization\n",
    "distruct_run = f'python /data/vitaled2/ref_panel/fastStructure/distruct.py\\\n",
    " -K 8\\\n",
    " --input={ref_panel}_final_structure\\\n",
    " --output={ref_panel}_distruct\\\n",
    " --popfile={ref_dir_path}/faststructure_labels.txt\\\n",
    " --title=\"GP2 Reference Panel Ancestries\"'\n",
    "\n",
    "print(distruct_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test faststructure with spanish GWAS data + ref panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test PCA with spanish GWAS data + ref panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps for detecting ancestry outliers used on spanish gwas data\n",
    "geno_path = '/data/vitaled2/test_data/spanish_gwas2/SPAIN2ndpart_pheno_call_rate_het_sex_heterozyg_hapmap_relatedness_variant'\n",
    "out_path = '/data/vitaled2/test_data/spanish_gwas2/'\n",
    "ref_path = '/data/LNG/vitaled2/1kgenomes/1kg_ashkj_ref_panel_final'\n",
    "\n",
    "bash1 = f\"plink --bfile {geno_path} --bmerge {ref_path} --out {out_path}bin_snplis --make-bed\"\n",
    "bash2 = f\"plink --bfile {geno_path} --flip {out_path}bin_snplis-merge.missnp --make-bed --out {geno_path}_flip\"\n",
    "bash3 = f\"plink --bfile {geno_path}_flip --bmerge {ref_path} --out {out_path}bin_snplis --make-bed\"\n",
    "bash4 = f\"plink --bfile {geno_path}_flip --exclude {out_path}bin_snplis-merge.missnp --out {geno_path}_flip_pruned --make-bed\"\n",
    "bash5 = f\"plink --bfile {geno_path}_flip_pruned --bmerge {ref_path} --out {out_path}bin_snplis --make-bed\"\n",
    "bash6 = f\"plink --bfile {out_path}bin_snplis --geno 0.01 --out {out_path}pca --make-bed --pca 8\"\n",
    "\n",
    "\n",
    "cmds = [bash1, bash2, bash3, bash4, bash5, bash6]\n",
    "\n",
    "# for cmd in cmds:\n",
    "#     shell_do(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_path = '/data/vitaled2/test_data/spanish_gwas2/pca.eigenvec'\n",
    "\n",
    "pca = pd.read_csv(pca_path, sep=' ', header=None)\n",
    "pca_columns = ['FID','IID'] + [f\"pc{i-1}\" for i in range(2,len(pca.columns))]\n",
    "pca.columns = pca_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples_path = f'{geno_path}.fam'\n",
    "new_samples_fam = pd.read_csv(new_samples_path, sep=' ', header=None)\n",
    "labeled_samples = new_samples_fam.loc[:,[0,1]]\n",
    "labeled_samples.loc[:,'label'] = 'new'\n",
    "labeled_samples.rename(columns={0:'FID',1:'IID'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine labeled samples with labeled ref panel ids and merge with pca\n",
    "combined_labels = labeled_samples.append(total_pruned_ref_df.loc[:, ['FID','IID','label']])\n",
    "# combined_labels\n",
    "labeled_pca = pca.merge(combined_labels, how='left', on=['FID','IID'])\n",
    "print(labeled_pca.label.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot PCs\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "cmap = cm.get_cmap('tab10')\n",
    "targets = list(labeled_pca.label.unique())\n",
    "targets = ['new', 'EUR']\n",
    "colors = cmap(np.linspace(0, 1, len(targets)))\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = labeled_pca['label'] == target\n",
    "    ax.scatter(labeled_pca.loc[indicesToKeep, 'pc1']\n",
    "               , labeled_pca.loc[indicesToKeep, 'pc2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{target:color for target,color in zip(targets,colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_list=['AJ', 'EUR', 'FIN', 'EAS', 'AMR', 'SAS', 'AAC', 'AFR']\n",
    "total_pop_list = pop_list.copy()\n",
    "total_pop_list.insert(0, 'new')\n",
    "print(pop_list)\n",
    "print(total_pop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_pca_outliers(pca_df, pop_list=['AJ', 'EUR', 'FIN', 'EAS', 'AMR', 'SAS', 'AAC', 'AFR'], new_sample_label='new'):\n",
    "#     total_pop_list = pop_list.copy()\n",
    "#     total_pop_list.insert(0, new_sample_label)\n",
    "    \n",
    "#     cmap = cm.get_cmap('tab10')\n",
    "#     colors = cmap(np.linspace(0, 1, len(total_pop_list)))\n",
    "#     colormap = {pop:color for pop,color in zip(total_pop_list,colors)}\n",
    "    \n",
    "#     for pop in pop_list:\n",
    "#         lowc1 = (pca_df.loc[(pca_df.label == pop), 'pc1'].mean()) - (6 * pca_df.loc[(pca_df.label == pop), 'pc1'].std())\n",
    "#         highc1 = (pca_df.loc[(pca_df.label == pop), 'pc1'].mean()) + (6 * pca_df.loc[(pca_df.label == pop), 'pc1'].std())\n",
    "#         lowc2 = (pca_df.loc[(pca_df.label == pop), 'pc2'].mean()) - (6 * pca_df.loc[(pca_df.label == pop), 'pc2'].std())\n",
    "#         highc2 = (pca_df.loc[(pca_df.label == pop), 'pc2'].mean()) + (6 * pca_df.loc[(pca_df.label == pop), 'pc2'].std())\n",
    "#         pruned_pca = pca_df.loc[(pca_df.pc1 >= lowc1) & (pca_df.pc1 <= highc1) & (pca_df.pc2 >= lowc2) & (pca_df.pc2 <= highc2)]\n",
    "        \n",
    "#         fig = plt.figure(figsize = (8,8))\n",
    "#         ax = fig.add_subplot(1,1,1) \n",
    "#         ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "#         ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "#         ax.set_title('2 component PCA', fontsize = 20)\n",
    "\n",
    "#         targets = [new_sample_label, pop]\n",
    "\n",
    "#         for target in targets:\n",
    "#             indicesToKeep = pruned_pca['label'] == target\n",
    "#             ax.scatter(pruned_pca.loc[indicesToKeep, 'pc1']\n",
    "#                        , pruned_pca.loc[indicesToKeep, 'pc2']\n",
    "#                        , c = colormap[target]\n",
    "#                        , s = 50)\n",
    "#         ax.legend(targets)\n",
    "#         ax.grid()\n",
    "\n",
    "\n",
    "        \n",
    "# detect_pca_outliers(labeled_pca)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruned_pca = labeled_pca.loc[(labeled_pca.pc1 >= lowc1) & (labeled_pca.pc1 <= highc1) & (labeled_pca.pc2 >= lowc2) & (labeled_pca.pc2 <= highc2)]\n",
    "\n",
    "# fig = plt.figure(figsize = (8,8))\n",
    "# ax = fig.add_subplot(1,1,1) \n",
    "# ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "# ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "# ax.set_title('2 component PCA', fontsize = 20)\n",
    "# cmap = cm.get_cmap('tab10')\n",
    "# targets = list(pruned_pca.label.unique())\n",
    "# # targets = ['new', 'EUR', 'AJ']\n",
    "# colors = cmap(np.linspace(0, 1, len(targets)))\n",
    "# for target, color in zip(targets,colors):\n",
    "#     indicesToKeep = pruned_pca['label'] == target\n",
    "#     ax.scatter(pruned_pca.loc[indicesToKeep, 'pc1']\n",
    "#                , pruned_pca.loc[indicesToKeep, 'pc2']\n",
    "#                , c = color\n",
    "#                , s = 50)\n",
    "# ax.legend(targets)\n",
    "# ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
